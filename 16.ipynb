{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8e2e7c-f460-47ba-8358-fcc28ac58abd",
   "metadata": {},
   "source": [
    "### __Implement Bayesian Neural Network on a given dataset, Calculate accuracy, precision and Recall for the same__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e6a8944-3217-40cb-b8fd-dff9700e82ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:99: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  loc = add_variable_fn(\n",
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:109: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  untransformed_scale = add_variable_fn(\n",
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 638ms/step - accuracy: 0.4375 - loss: 1.1056 - val_accuracy: 0.2917 - val_loss: 1.1998\n",
      "Epoch 2/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3203 - loss: 1.1173 - val_accuracy: 0.3750 - val_loss: 1.1736\n",
      "Epoch 3/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3958 - loss: 1.1141 - val_accuracy: 0.2083 - val_loss: 1.1822\n",
      "Epoch 4/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3906 - loss: 1.1207 - val_accuracy: 0.2917 - val_loss: 1.1624\n",
      "Epoch 5/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2786 - loss: 1.0989 - val_accuracy: 0.2500 - val_loss: 1.2376\n",
      "Epoch 6/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3945 - loss: 1.1130 - val_accuracy: 0.2917 - val_loss: 1.2134\n",
      "Epoch 7/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4193 - loss: 1.1079 - val_accuracy: 0.2500 - val_loss: 1.1784\n",
      "Epoch 8/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4245 - loss: 1.1043 - val_accuracy: 0.2083 - val_loss: 1.2291\n",
      "Epoch 9/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3594 - loss: 1.1221 - val_accuracy: 0.4583 - val_loss: 1.1315\n",
      "Epoch 10/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3711 - loss: 1.1232 - val_accuracy: 0.3333 - val_loss: 1.1706\n",
      "Epoch 11/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3620 - loss: 1.1190 - val_accuracy: 0.2083 - val_loss: 1.2094\n",
      "Epoch 12/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3047 - loss: 1.1346 - val_accuracy: 0.1250 - val_loss: 1.1743\n",
      "Epoch 13/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3776 - loss: 1.1038 - val_accuracy: 0.2083 - val_loss: 1.1949\n",
      "Epoch 14/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3750 - loss: 1.0998 - val_accuracy: 0.3750 - val_loss: 1.1418\n",
      "Epoch 15/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4102 - loss: 1.1034 - val_accuracy: 0.2917 - val_loss: 1.2029\n",
      "Epoch 16/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3464 - loss: 1.1099 - val_accuracy: 0.1250 - val_loss: 1.2192\n",
      "Epoch 17/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4427 - loss: 1.0771 - val_accuracy: 0.2917 - val_loss: 1.2253\n",
      "Epoch 18/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3242 - loss: 1.1248 - val_accuracy: 0.1667 - val_loss: 1.2065\n",
      "Epoch 19/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3424 - loss: 1.1090 - val_accuracy: 0.0833 - val_loss: 1.3041\n",
      "Epoch 20/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3958 - loss: 1.1040 - val_accuracy: 0.3333 - val_loss: 1.1811\n",
      "Epoch 21/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3711 - loss: 1.1185 - val_accuracy: 0.2500 - val_loss: 1.2317\n",
      "Epoch 22/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4089 - loss: 1.1292 - val_accuracy: 0.2500 - val_loss: 1.2024\n",
      "Epoch 23/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3555 - loss: 1.1119 - val_accuracy: 0.3333 - val_loss: 1.1580\n",
      "Epoch 24/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2682 - loss: 1.1454 - val_accuracy: 0.1667 - val_loss: 1.2071\n",
      "Epoch 25/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3594 - loss: 1.1179 - val_accuracy: 0.2917 - val_loss: 1.2130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749ms/step\n",
      "Accuracy: 0.3667\n",
      "Precision: 0.2296\n",
      "Recall: 0.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare the Iris dataset\n",
    "df = sns.load_dataset('iris')\n",
    "x = df.drop(columns=['species'])\n",
    "y = df['species']\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model using tf.keras.Model\n",
    "class BayesianNN(Model):\n",
    "    def __init__(self):\n",
    "        super(BayesianNN, self).__init__()\n",
    "        # Define the DenseFlipout layers\n",
    "        self.dense1 = tfp.layers.DenseFlipout(64, activation='relu')\n",
    "        self.dense2 = tfp.layers.DenseFlipout(32, activation='relu')\n",
    "        self.dense3 = tfp.layers.DenseFlipout(3, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "# Create and compile the Bayesian Neural Network\n",
    "model = BayesianNN()\n",
    "model.build(input_shape=(None, x_train.shape[1]))  # Set input shape for the model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e25221d5-77c4-4367-9069-23acf4b5012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-probability[tf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488da92d-52e5-4d12-ae3a-c9f8d2fb94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow --no-warn-script-location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c102dd3-5344-44b0-a4bd-abc8224a5aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
